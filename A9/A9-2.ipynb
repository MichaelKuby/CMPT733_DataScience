{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 9: Causal Inference (Part 2)\n",
    "\n",
    "## Objective:\n",
    "\n",
    "Causal inference is the process of drawing a conclusion about a causal connection based on the conditions of the occurrence of an effect. It is a very powerful and widely-used tool in real-world applications and scenarios. In this assignment, you are expected to apply the basic concepts of causal inference to solve problems on real datasets and be able to achieve the following goals.\n",
    "\n",
    "* Understand why causality is needed.\n",
    "* Understand what is causality, particularly the difference between causality and correlation.\n",
    "* Understand how to estimate counterfactual results.\n",
    "* Understand how to use the graphical model to represent causality.\n",
    "* Can use some tools (e.g., dowhy) to infer causality, express causality and estimate treatment effects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataprep.eda import plot\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you are going to use the [Lalonde](lalonde.csv) dataset. Each tuple in the dataset represents an individual who was enrolled (or not enrolled) in a job training program. It aims to evaluate the effectiveness of a job training program (the treatment variable) on the real earnings of an individual, after completing the program for years. \n",
    "\n",
    "The dataset consists of a number of demographic variables, like age, race, academic background, marriage status, and previous real earnings in 1974, 1975 as well as a treatment indicator, and the real earnings in the year 1978 (the outcome variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treat</th>\n",
       "      <th>age</th>\n",
       "      <th>educ</th>\n",
       "      <th>black</th>\n",
       "      <th>hispan</th>\n",
       "      <th>married</th>\n",
       "      <th>nodegree</th>\n",
       "      <th>re74</th>\n",
       "      <th>re75</th>\n",
       "      <th>re78</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NSW1</th>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9930.0460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NSW2</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3595.8940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NSW3</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24909.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NSW4</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7506.1460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NSW5</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>289.7899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSID420</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>964.9555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSID421</th>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSID422</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5551.8190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSID423</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7543.7940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSID424</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>609 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         treat  age  educ  black  hispan  married  nodegree  re74  re75  \\\n",
       "id                                                                        \n",
       "NSW1         1   37    11      1       0        1         1   0.0   0.0   \n",
       "NSW2         1   22     9      0       1        0         1   0.0   0.0   \n",
       "NSW3         1   30    12      1       0        0         0   0.0   0.0   \n",
       "NSW4         1   27    11      1       0        0         1   0.0   0.0   \n",
       "NSW5         1   33     8      1       0        0         1   0.0   0.0   \n",
       "...        ...  ...   ...    ...     ...      ...       ...   ...   ...   \n",
       "PSID420      0   39     2      1       0        1         1   0.0   0.0   \n",
       "PSID421      0   55     8      0       0        1         1   0.0   0.0   \n",
       "PSID422      0   16     9      0       0        0         1   0.0   0.0   \n",
       "PSID423      0   27    10      1       0        0         1   0.0   0.0   \n",
       "PSID424      0   25    14      0       0        0         0   0.0   0.0   \n",
       "\n",
       "               re78  \n",
       "id                   \n",
       "NSW1      9930.0460  \n",
       "NSW2      3595.8940  \n",
       "NSW3     24909.4500  \n",
       "NSW4      7506.1460  \n",
       "NSW5       289.7899  \n",
       "...             ...  \n",
       "PSID420    964.9555  \n",
       "PSID421      0.0000  \n",
       "PSID422   5551.8190  \n",
       "PSID423   7543.7940  \n",
       "PSID424      0.0000  \n",
       "\n",
       "[609 rows x 10 columns]"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lalonde = pd.read_csv('lalonde.csv', index_col=0)\n",
    "lalonde.head(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(lalonde)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Causal Graph \n",
    "In this task, you will draw a causal graph on a real-world dataset based on the information given. Please remind yourself of the difference between causality and correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import graphviz, the python tool we are going to use for this task\n",
    "from graphviz import Digraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Lalonde dataset, `treat` is the treatment attribute, which represents whether an individual was enrolled in the job training program or not. `re78` is the outcome attribute. `age` and `married` are confounding variables. Please draw the causal graph for these four attributes using Graphviz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 9.0.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"305pt\" height=\"44pt\"\n",
       " viewBox=\"0.00 0.00 304.59 44.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 40)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-40 300.59,-40 300.59,4 -4,4\"/>\n",
       "<!-- a -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>a</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27.3\" cy=\"-18\" rx=\"27.3\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27.3\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">treat</text>\n",
       "</g>\n",
       "<!-- b -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>b</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"99.3\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"99.3\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">age</text>\n",
       "</g>\n",
       "<!-- c -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>c</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"184.3\" cy=\"-18\" rx=\"40.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"184.3\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">married</text>\n",
       "</g>\n",
       "<!-- d -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>d</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"269.3\" cy=\"-18\" rx=\"27.3\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"269.3\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">re78</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x1517fa0d0>"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot = Digraph(comment='The causal graph for Lalonde')\n",
    "dot.node('a','treat')\n",
    "dot.node('b','age')\n",
    "dot.node('c','married')\n",
    "dot.node('d','re78')\n",
    "\n",
    "dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 9.0.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"172pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 172.09 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-184 168.09,-184 168.09,4 -4,4\"/>\n",
       "<!-- a -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>a</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"76\" cy=\"-90\" rx=\"27.3\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"76\" y=\"-84.95\" font-family=\"Times,serif\" font-size=\"14.00\">treat</text>\n",
       "</g>\n",
       "<!-- d -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>d</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"76\" cy=\"-18\" rx=\"27.3\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"76\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">re78</text>\n",
       "</g>\n",
       "<!-- a&#45;&gt;d -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>a&#45;&gt;d</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M76,-71.7C76,-64.41 76,-55.73 76,-47.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"79.5,-47.62 76,-37.62 72.5,-47.62 79.5,-47.62\"/>\n",
       "</g>\n",
       "<!-- b -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>b</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-156.95\" font-family=\"Times,serif\" font-size=\"14.00\">age</text>\n",
       "</g>\n",
       "<!-- b&#45;&gt;a -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>b&#45;&gt;a</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M38.12,-145.12C44.13,-136.52 51.7,-125.72 58.49,-116.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"61.19,-118.26 64.06,-108.06 55.46,-114.25 61.19,-118.26\"/>\n",
       "</g>\n",
       "<!-- b&#45;&gt;d -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>b&#45;&gt;d</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M27.25,-143.69C28.03,-125.32 30.78,-95.72 40,-72 43.92,-61.91 50.07,-51.82 56.18,-43.21\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"58.85,-45.49 62.04,-35.38 53.24,-41.29 58.85,-45.49\"/>\n",
       "</g>\n",
       "<!-- c -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>c</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"124\" cy=\"-162\" rx=\"40.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"124\" y=\"-156.95\" font-family=\"Times,serif\" font-size=\"14.00\">married</text>\n",
       "</g>\n",
       "<!-- c&#45;&gt;a -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>c&#45;&gt;a</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M112.62,-144.41C106.86,-136.01 99.75,-125.63 93.32,-116.26\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"96.36,-114.5 87.82,-108.24 90.59,-118.46 96.36,-114.5\"/>\n",
       "</g>\n",
       "<!-- c&#45;&gt;d -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>c&#45;&gt;d</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M123.99,-143.69C123.46,-125.33 121.08,-95.74 112,-72 108.13,-61.89 102,-51.8 95.88,-43.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"98.82,-41.26 90.02,-35.36 93.22,-45.46 98.82,-41.26\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x1517fa0d0>"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#<-- Write Your Code -->\n",
    "#Implement your plot function here and show the graph, the output should be a causal graph\n",
    "\n",
    "dot.edge('a', 'd')\n",
    "dot.edge('b', 'a')\n",
    "dot.edge('c', 'a')\n",
    "dot.edge('c', 'd')\n",
    "dot.edge('b', 'd')\n",
    "\n",
    "dot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. ATE Estimation\n",
    "In this task, your job is to implement different ATE estimation approaches and draw useful conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Perfect Matching\n",
    "For the PSID tuples in the dataset (i.e., those individuals who weren't enrolled in the job training program), please use perfect matching to estimate their salaries if they received treatments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_first_match_row(df, x):\n",
    "    # Drop the treatment column and the target column from x\n",
    "    x_modified = x.drop(labels=['treat', 're78'])\n",
    "    \n",
    "    # Drop the treatment column and the target column\n",
    "    temp_df = df.drop(columns=['treat', 're78'])\n",
    "\n",
    "    # Find the first row of treatment_df that matches x. x is a row of the lalonde dataset\n",
    "    for i in range(len(temp_df)):\n",
    "        if temp_df.iloc[i].equals(x_modified):\n",
    "            # return the row of the first match\n",
    "            return df.iloc[i]['re78']\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<-- Write Your Code -->\n",
    "\n",
    "# Implement the perfect matching method here and output the count of PSID tuples whose counterfactual can be computed\n",
    "# using perfect matching, as well as the percentage of such tuples among all PSID tuples. If there are multiple \n",
    "# tuples in the treatment group that can be matched with the control group, just select the first one\n",
    "# output: count and percentage\n",
    "\n",
    "control_df = lalonde[lalonde['treat'] == 0]\n",
    "treatment_df = lalonde[lalonde['treat'] == 1]\n",
    "\n",
    "# Create control_df with counterfactual re78\n",
    "control_df['perfect match counterfactual re78'] = control_df.apply(lambda x: find_first_match_row(treatment_df, x), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the count of the number of counterfactuals that did not return -1\n",
    "count = control_df[control_df['perfect match counterfactual re78'] != -1].shape[0]\n",
    "\n",
    "# Get the percentage of the number of counterfactuals that did not return -1\n",
    "percentage = count / control_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of tuples which can be computed by perfect matching is 12\n",
      "Percentage of such tuples among all PSID tuples is 0.027972027972027972\n"
     ]
    }
   ],
   "source": [
    "# Run the following code to print out the result\n",
    "print(\"Count of tuples which can be computed by perfect matching is \" + str(count))\n",
    "print(\"Percentage of such tuples among all PSID tuples is \" + str(percentage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<-- Write Your Code -->\n",
    "\n",
    "# Compute ATE among those PSID tuples whose counterfactual can be computed using perfect matching\n",
    "# output: value of ATE\n",
    "\n",
    "perfect_matches = control_df[control_df['perfect match counterfactual re78'] != -1]\n",
    "perfect_matches['diff'] = perfect_matches['perfect match counterfactual re78'] - perfect_matches['re78']\n",
    "ATE = perfect_matches['diff'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE by perfect matching is 1362.394\n"
     ]
    }
   ],
   "source": [
    "# Run following code to print the result\n",
    "print(\"ATE by perfect matching is \" + str(ATE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Nearest Neighbor Matching\n",
    "For the PSID tuples in the dataset (i.e., those who weren't enrolled in the job training program), please use the nearest neighbor matching to estimate their salaries if they received treatments.\n",
    "\n",
    "Please use all covariates (the attributes besides treatment and outcome) and use Euclidean distance as the distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<-- Write Your Code -->\n",
    "\n",
    "# Implement the nearest neighbor matching method here and output the count of PSID tuples whose counterfactual can be\n",
    "# computed using nearest neighbor matching, when the threshold is set to 1000, as well as the percentage of such tuples among all PSID tuples\n",
    "# Output: count and percentage\n",
    "\n",
    "# Please use np.linalg.norm(x1 - x2) to compute the euclidean distance between two vectors\n",
    "\n",
    "def nearest_neighbour(df, x):\n",
    "    # Drop the treatment column and the target column from x\n",
    "    x_modified = x.drop(labels=['treat', 're78'])\n",
    "    \n",
    "    # Drop the treatment column and the target column\n",
    "    temp_df = df.drop(columns=['treat', 're78'])\n",
    "\n",
    "    # Find the first row of treatment_df that matches x. x is a row of the lalonde dataset\n",
    "    for i in range(len(temp_df)):\n",
    "        if np.linalg.norm(temp_df.iloc[i] - x_modified) < 1000:\n",
    "            # return the row of the first match\n",
    "            return df.iloc[i]['re78']\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_df = lalonde[lalonde['treat'] == 0]\n",
    "treatment_df = lalonde[lalonde['treat'] == 1]\n",
    "\n",
    "# Create control_df with nearest neighbour counterfactual re78\n",
    "control_df['nearest neighbour counterfactual re78'] = control_df.apply(lambda x: nearest_neighbour(treatment_df, x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the count of the number of counterfactuals that did not return -1\n",
    "count = control_df[control_df['nearest neighbour counterfactual re78'] != -1].shape[0]\n",
    "\n",
    "# Get the percentage of the number of counterfactuals that did not return -1\n",
    "percentage = count / control_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of tuples which can be computed by nearest neighbor matching is 318\n",
      "Percentage of such tuples among all PSID tuples is 0.7412587412587412\n"
     ]
    }
   ],
   "source": [
    "#run following code to print the result\n",
    "print(\"Count of tuples which can be computed by nearest neighbor matching is \" + str(count))\n",
    "print(\"Percentage of such tuples among all PSID tuples is \" + str(percentage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<-- Write Your Code -->\n",
    "\n",
    "# Compute ATE among those PSID tuples whose counterfactual can be computed using nearest neighbor matching\n",
    "# Output: value of ATE\n",
    "\n",
    "nearest_neighbour_matches = control_df[control_df['nearest neighbour counterfactual re78'] != -1]\n",
    "nearest_neighbour_matches['diff'] = nearest_neighbour_matches['nearest neighbour counterfactual re78'] - nearest_neighbour_matches['re78']\n",
    "ATE = nearest_neighbour_matches['diff'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE by nearest neighbor matching is 1304.973885062893\n"
     ]
    }
   ],
   "source": [
    "# Run following code to print out the result\n",
    "print(\"ATE by nearest neighbor matching is \" + str(ATE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Propensity Score Matching\n",
    "For the PSID tuples in the dataset (i.e., those weren't enrolled in the job training program), please use propensity score matching to estimate their salaries if they received treatments.\n",
    "\n",
    "Please use logistic regression to fit the propensity score.\n",
    "\n",
    "## What is Propensity Score?\n",
    "\n",
    "The propensity score is the probability of a unit (e.g., individual, school, hospital) receiving a treatment given a set of observed covariates. It is typically estimated using logistic regression, where the treatment assignment is the dependent variable and the covariates are the independent variables. The logistic regression model estimates the probability (ranging from 0 to 1) of each unit being in the treatment group based on the covariates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<-- Write Your Code -->\n",
    "\n",
    "# Compute propensity score P(y = 1|X) for each tuple in the dataset. Use logistic regression.\n",
    "# Output: add the new column \"psm\" to lalonde dataframe\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X = lalonde.drop(columns=['treat', 're78'])\n",
    "y = lalonde['treat']\n",
    "\n",
    "# Scale X between 0-1\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into X and y, using all the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "logisticRegr = LogisticRegression()\n",
    "\n",
    "estimator = logisticRegr.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "score = estimator.score(X_test, y_test)\n",
    "\n",
    "# Add the new column 'psm' to lalonde dataframe\n",
    "predictions = estimator.predict_proba(X)\n",
    "lalonde['psm'] = predictions[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treat</th>\n",
       "      <th>age</th>\n",
       "      <th>educ</th>\n",
       "      <th>black</th>\n",
       "      <th>hispan</th>\n",
       "      <th>married</th>\n",
       "      <th>nodegree</th>\n",
       "      <th>re74</th>\n",
       "      <th>re75</th>\n",
       "      <th>re78</th>\n",
       "      <th>psm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NSW1</th>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9930.0460</td>\n",
       "      <td>0.533057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NSW2</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3595.8940</td>\n",
       "      <td>0.220383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NSW3</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24909.4500</td>\n",
       "      <td>0.630276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NSW4</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7506.1460</td>\n",
       "      <td>0.710548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NSW5</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>289.7899</td>\n",
       "      <td>0.684550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSID420</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>964.9555</td>\n",
       "      <td>0.427877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSID421</th>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.074528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSID422</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5551.8190</td>\n",
       "      <td>0.141609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSID423</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7543.7940</td>\n",
       "      <td>0.700633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSID424</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.123922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>609 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         treat  age  educ  black  hispan  married  nodegree  re74  re75  \\\n",
       "id                                                                        \n",
       "NSW1         1   37    11      1       0        1         1   0.0   0.0   \n",
       "NSW2         1   22     9      0       1        0         1   0.0   0.0   \n",
       "NSW3         1   30    12      1       0        0         0   0.0   0.0   \n",
       "NSW4         1   27    11      1       0        0         1   0.0   0.0   \n",
       "NSW5         1   33     8      1       0        0         1   0.0   0.0   \n",
       "...        ...  ...   ...    ...     ...      ...       ...   ...   ...   \n",
       "PSID420      0   39     2      1       0        1         1   0.0   0.0   \n",
       "PSID421      0   55     8      0       0        1         1   0.0   0.0   \n",
       "PSID422      0   16     9      0       0        0         1   0.0   0.0   \n",
       "PSID423      0   27    10      1       0        0         1   0.0   0.0   \n",
       "PSID424      0   25    14      0       0        0         0   0.0   0.0   \n",
       "\n",
       "               re78       psm  \n",
       "id                             \n",
       "NSW1      9930.0460  0.533057  \n",
       "NSW2      3595.8940  0.220383  \n",
       "NSW3     24909.4500  0.630276  \n",
       "NSW4      7506.1460  0.710548  \n",
       "NSW5       289.7899  0.684550  \n",
       "...             ...       ...  \n",
       "PSID420    964.9555  0.427877  \n",
       "PSID421      0.0000  0.074528  \n",
       "PSID422   5551.8190  0.141609  \n",
       "PSID423   7543.7940  0.700633  \n",
       "PSID424      0.0000  0.123922  \n",
       "\n",
       "[609 rows x 11 columns]"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the following code to see the result\n",
    "lalonde.head(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<-- Write Your Code -->\n",
    "\n",
    "# For each tuple in the control group, find the matching tuple in the treatment group, and then compute\n",
    "# the ATE over the population\n",
    "# Please match tuples with the metric |psm1 - psm2| to be minimum, threhold set to 0.01\n",
    "# Output: the value of ATE, the count of tuples that can be matched, as well as the percentage\n",
    "\n",
    "def psm_match(df, x):\n",
    "    # Drop the treatment column and the target column from x\n",
    "    x_modified = x.drop(labels=['treat', 're78'])\n",
    "    \n",
    "    # Drop the treatment column and the target column\n",
    "    temp_df = df.drop(columns=['treat', 're78'])\n",
    "\n",
    "    possible_matches = []\n",
    "\n",
    "    # Find the first row of treatment_df that matches x. x is a row of the lalonde dataset\n",
    "    for i in range(len(temp_df)):\n",
    "        if abs(temp_df.iloc[i]['psm'] - x_modified['psm']) < 0.01:\n",
    "            # add the matche to all possible matches\n",
    "            possible_matches.append((i, abs(temp_df.iloc[i]['psm'] - x_modified['psm'])))\n",
    "    \n",
    "    if len(possible_matches) == 0:\n",
    "        return -1\n",
    "    else:\n",
    "        # sort possible_matches by the second element of the tuple\n",
    "        possible_matches = sorted(possible_matches, key=lambda x: x[1])\n",
    "        # return the the re78 col of the first match\n",
    "        return df.iloc[possible_matches[0][0]]['re78']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_df = lalonde[lalonde['treat'] == 0]\n",
    "treatment_df = lalonde[lalonde['treat'] == 1]\n",
    "\n",
    "# Create control_df with counterfactual re78\n",
    "control_df['psm match counterfactual re78'] = control_df.apply(lambda x: psm_match(treatment_df, x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the count of control_df['psm match counterfactual re78'] that are not -1\n",
    "count = control_df[control_df['psm match counterfactual re78'] != -1].shape[0]\n",
    "\n",
    "# Compute the percentage of control_df['psm match counterfactual re78'] that are not -1\n",
    "percentage = count / control_df.shape[0]\n",
    "\n",
    "# Compute the ATE\n",
    "psm_matches = control_df[control_df['psm match counterfactual re78'] != -1]\n",
    "psm_matches['diff'] = psm_matches['psm match counterfactual re78'] - psm_matches['re78']\n",
    "ATE = psm_matches['diff'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE by propensity score matching is 485.39996406649624\n",
      "Count of tuples which can be computed by propensity score matching is 391\n",
      "Percentage of such tuples among all PSID tuples is 0.9114219114219114\n"
     ]
    }
   ],
   "source": [
    "# Run the following code to print out the result\n",
    "print(\"ATE by propensity score matching is \" + str(ATE))\n",
    "print(\"Count of tuples which can be computed by propensity score matching is \" + str(count))\n",
    "print(\"Percentage of such tuples among all PSID tuples is \" + str(percentage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Linear Regression\n",
    "Train two individual models to fit P(y|t = 1,X) and P(y|t = 0,X), then infer the counterfactual outcome using two models while setting treatment to the opposite value. Infer the ATE over the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<-- Write Your Code -->\n",
    "\n",
    "# Train two individual linear regression models and infer the counterfactual result for each tuple\n",
    "# Output: the value of ATE, over the population\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "control_df = lalonde[lalonde['treat'] == 0]\n",
    "treatment_df = lalonde[lalonde['treat'] == 1]\n",
    "\n",
    "# Separate features and target\n",
    "X_control = control_df.drop(columns=['treat', 're78'])\n",
    "y_control = control_df['re78']\n",
    "X_treatment = treatment_df.drop(columns=['treat', 're78'])\n",
    "y_treatment = treatment_df['re78']\n",
    "\n",
    "# Scale X between 0-1\n",
    "scaler = MinMaxScaler()\n",
    "X_control_scaled = scaler.fit_transform(X_control)\n",
    "X_treatment_scaled = scaler.transform(X_treatment)\n",
    "\n",
    "lrm_control = LinearRegression()\n",
    "lrm_treatment = LinearRegression()\n",
    "\n",
    "# Train the models\n",
    "lrm_control = lrm_control.fit(X_control_scaled, y_control)\n",
    "lrm_treatment = lrm_treatment.fit(X_treatment_scaled, y_treatment)\n",
    "\n",
    "# Predict counterfactual outcomes\n",
    "control_df['linear regression counterfactual re78'] = lrm_treatment.predict(X_control_scaled)\n",
    "treatment_df['linear regression counterfactual re78'] = lrm_control.predict(X_treatment_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the differences between the counterfactual re78 and the actual re78 for both control_df and treatment_df\n",
    "control_df['diff'] = control_df['linear regression counterfactual re78'] - control_df['re78']\n",
    "treatment_df['diff'] = treatment_df['linear regression counterfactual re78'] - treatment_df['re78']\n",
    "\n",
    "# Compute the ATE over the population\n",
    "ATE = (control_df['diff'].sum() + treatment_df['diff'].sum()) / len(lalonde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE by linear regression is -921.3810233844376\n"
     ]
    }
   ],
   "source": [
    "# Run following code to print out the result\n",
    "print(\"ATE by linear regression is \" + str(ATE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please briefly discuss the advantages and disadvantages of the above four approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. <u>Perfect Matching</u>\n",
    "\n",
    "    *Advantage*: Perfect matching is very easy to understand. Given two records that have identical features except for their treatment, we can directly infer counterfactuals.\n",
    "\n",
    "    *Advantage*: Accuracy. It would seem that since the two records have identical features outside of their treatment, the counterfactual computed should be very accurate.\n",
    "\n",
    "    *Disadvantage*: Few matches. For most datasets, perfect matching is unlikely to generate a proportionally large number of matches since finding a record in the treatment data that is identical is uncommon, and will become increasingly uncommon the more features we have.\n",
    "\n",
    "2. <u>Nearest Neighbour</u>\n",
    "\n",
    "    *Advantage*: More matches. Because it finds matches that are close, but not perfect, it has the flexibility of being able to compute many more counterfactuals than Perfect Matching is able to.\n",
    "\n",
    "    *Disadvantage*: Potentially inaccurate. Depending on the metric used to compute the distance between records and the matches that are created, it is possible to end up computing counterfactuals that are inaccurate.\n",
    "\n",
    "3. <u>Propensity Score Matching</u>\n",
    "\n",
    "    *Advantage*: Simplicity through dimensionality reduction. By using a single feature to identify matches that is computed based on each of the original features, PSM is effectively doing dimensionality reduction.\n",
    "\n",
    "    *Advantage*: More matches. Similar to Nearest Neighbour, because of the flexibility in the approach, we have the ability to compute many more counterfactuals than perfect matching is able to.\n",
    "\n",
    "    *Disadvantage*: Potentially inaccurate. We are relying heavily on a single metric that is computed through a logistic regression model. If the model itself is poor, so too will our matches be poor.\n",
    "\n",
    "4. <u>Linear Regression</u>\n",
    "\n",
    "    *Advantage*: Easy to understand. Linear regression is a simple method that is well understood. We can analyze the coefficients if we are interested in the inner workings of the predictions, making the model highly interpretable.\n",
    "\n",
    "    *Disadvantage*: Linear regression assumes that there is a linear relationship between the inputs and the response. If this does not hold, then our results are unlikely to be accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. DoWhy\n",
    "In this task, you are required to apply DoWhy and analyze the dataset using two ATE estimation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Causal Graph not provided. DoWhy will construct a graph based on data inputs.\n",
      "There are an additional 3 variables in the dataset that are not in the graph. Variable names are: '['psm', 're74', 're75']'\n"
     ]
    }
   ],
   "source": [
    "from dowhy import CausalModel\n",
    "\n",
    "# Step 1: Create a causal model from the data\n",
    "\n",
    "lalonde['treat'] = lalonde['treat'].astype(bool)\n",
    "model = CausalModel(\n",
    "        data = lalonde,\n",
    "        treatment='treat',\n",
    "        outcome='re78',\n",
    "        common_causes='nodegree+black+hispan+age+educ+married'.split('+'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<-- Write Your Code -->\n",
    "\n",
    "# Use the linear regression and PSM methods provided by DoWhy to estimate ATE \n",
    "# Output: ATE_linear, ATE_psm\n",
    "\n",
    "# Linear Regression\n",
    "\n",
    "# Step 2: Identify causal effect and return target estimands\n",
    "identified_estimand = model.identify_effect()\n",
    "\n",
    "# Step 3: Estimate the target estimand using linear regression\n",
    "estimate = model.estimate_effect(identified_estimand, method_name=\"backdoor.linear_regression\")\n",
    "\n",
    "# Get the ATE from the estimate\n",
    "ATE_linear = estimate.value\n",
    "\n",
    "# Propensity Score Matching\n",
    "\n",
    "# Step 3A: Estimate the target estimand using propensity score matching\n",
    "estimate = model.estimate_effect(identified_estimand, method_name=\"backdoor.propensity_score_matching\")\n",
    "\n",
    "# Get the ATE from the estimate\n",
    "ATE_psm = estimate.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE by linear regression is 1163.9223548829013\n",
      "ATE by psm is 285.6763360423455\n"
     ]
    }
   ],
   "source": [
    "# Run following code to print out the result\n",
    "print(\"ATE by linear regression is \" + str(ATE_linear))\n",
    "print(\"ATE by psm is \" + str(ATE_psm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Briefly explain why the result by DoWhy is not same as the result by your own implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A.** \n",
    "\n",
    "1. <u>Linear Regression</u>\n",
    "\n",
    "    The Linear Regression model that I trained myself used re74 and re75 during training, whereas the way that the model was specified for DoWhy does not include those features.\n",
    "\n",
    "    It is not clear what DoWhy used for data preprocessing. If DoWhy implemented a scaling or transformation that differs from what I did, the ATE estimates will also differ.\n",
    "\n",
    "    DoWhy may have used a form of regularization on the linear regression model that I did not use.\n",
    "\n",
    "    I trained my model on 80% of the data (via test_train_split), and I am not sure if this was the correct approach or if I should have used all of the data. DoWhy likely optimizes this and may have implemented this differently.\n",
    "\n",
    "2. <u>Propensity Score Matching</u>\n",
    "\n",
    "    We used a threshold of 0.01, but this was fairly arbitrarily set and could easily differ in DoWhy's implementation.\n",
    "\n",
    "    Again, I trained the logistic regression model using re74 and re75. It's possible that I should have left these features out. For DoWhy, since they are not included in `common_causes`, they will not be considered in the PSM implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the code in this notebook, and submit it to the CourSys activity Assignment 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
