{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 11-1: Fairness in Machine Learning\n",
    "\n",
    "## Objectives\n",
    "\n",
    "In this assignment, you will learn how to use [AI Fairness 360](http://aif360.mybluemix.net/) to detect and repair bias in machine learning. \n",
    "\n",
    "Task 1 is a reading task. It is a tutorial helping you understand the basics of AI Fairness 360. Task 2 is the one that requires you to complete.\n",
    "\n",
    "\n",
    "## Task 1. AI Fairness 360 Tutorial"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biases and Machine Learning\n",
    "A machine learning model makes predictions of an outcome for a particular instance. (Given an instance of a loan application, predict if the applicant will repay the loan.) The model makes these predictions based on a training dataset, where many other instances (other loan applications) and actual outcomes (whether they repaid) are provided. Thus, a machine learning algorithm will attempt to find patterns, or generalizations, in the training dataset to use when a prediction for a new instance is needed. (For example, one pattern it might discover is \"if a person has salary > USD 40K and has outstanding debt < USD 5, they will repay the loan\".) In many domains this technique, called supervised machine learning, has worked very well.\n",
    "\n",
    "However, sometimes the patterns that are found may not be desirable or may even be illegal. For example, a loan repay model may determine that age plays a significant role in the prediction of repayment because the training dataset happened to have better repayment for one age group than for another. This raises two problems: 1) the training dataset may not be representative of the true population of people of all age groups, and 2) even if it is representative, it is illegal to base any decision on a applicant's age alone, regardless of whether this is a good prediction based on historical data.\n",
    "\n",
    "AI Fairness 360 is designed to help address this problem with *fairness metrics* and *bias mitigators*.  Fairness metrics can be used to check for bias in machine learning workflows.  Bias mitigators can be used to overcome bias in the workflow to produce a more fair outcome. \n",
    "\n",
    "The loan scenario describes an intuitive example of illegal bias. However, not all undesirable bias in machine learning is illegal it may also exist in more subtle ways.  For example, a loan company may want a diverse portfolio of customers across all income levels, and thus, will deem it undesirable if they are making more loans to high income levels over low income levels.  Although this is not illegal or unethical, it is undesirable for the company's strategy.\n",
    "\n",
    "As these two examples illustrate, a bias detection and/or mitigation toolkit needs to be tailored to the particular bias of interest.  More specifically, it needs to know the attribute or attributes, called *protected attributes*, that are of interest: race is one example of a *protected attribute* and age is a second.\n",
    "\n",
    "### The Machine Learning Workflow\n",
    "To understand how bias can enter a machine learning model, we first review the basics of how a model is created in a supervised machine learning process.  \n",
    "\n",
    "\n",
    "\n",
    "![image](ai360.jpeg)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "First, the process starts with a *training dataset*, which contains a sequence of instances, where each instance has two components: the features and the correct prediction for those features.  Next, a machine learning algorithm is trained on this training dataset to produce a machine learning model.  This generated model can be used to make a prediction when given a new instance.  A second dataset with features and correct predictions, called a *test dataset*, is used to assess the accuracy of the model.\n",
    "Since this test dataset is the same format as the training dataset, a set of instances of features and prediction pairs, often these two datasets derive from the same initial dataset.  A random partitioning algorithm is used to split the initial dataset into training and test datasets.\n",
    "\n",
    "Bias can enter the system in any of the three steps above.  The training data set may be biased in that its outcomes may be biased towards particular kinds of instances.  The algorithm that creates the model may be biased in that it may generate models that are weighted towards particular features in the input. The test data set may be biased in that it has expectations on correct answers that may be biased.  These three points in the machine learning process represent points for testing and mitigating bias.  In AI Fairness 360 codebase, we call these points *pre-processing*, *in-processing*, and *post-processing*. \n",
    "\n",
    "### AI Fairness 360\n",
    "We are now ready to utilize AI Fairness 360 (`aif360`) to detect and mitigate bias.  We will use the German credit dataset, splitting it into a training and test dataset.  We will look for bias in the creation of a machine learning model to predict if an applicant should be given credit based on various features from a typical credit application.  The protected attribute will be \"Age\", with \"1\" (older than or equal to 25) and \"0\" (younger than 25) being the values for the privileged and unprivileged groups, respectively.\n",
    "For this first tutorial, we will check for bias in the initial training data, mitigate the bias, and recheck.  More sophisticated machine learning workflows are given in the author tutorials and demo notebooks in the codebase.\n",
    "\n",
    "Here are the steps involved\n",
    "#### Step 1: Write import statements\n",
    "#### Step 2: Set bias detection options, load dataset, and split between train and test\n",
    "#### Step 3: Compute fairness metric on original training dataset\n",
    "#### Step 4: Mitigate bias by transforming the original dataset\n",
    "#### Step 5: Compute fairness metric on transformed training dataset\n",
    "\n",
    "### Step 1 Import Statements\n",
    "As with any python program, the first step will be to import the necessary packages.  Below we import several components from the `aif360` package.  We import the GermanDataset, metrics to check for bias, and classes related to the algorithm we will use to mitigate bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
      "pip install 'aif360[inFairness]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n"
     ]
    }
   ],
   "source": [
    "# Load all necessary packages\n",
    "import sys\n",
    "sys.path.insert(1, \"../\")  \n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "from aif360.datasets import GermanDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 Load dataset, specifying protected attribute, and split dataset into train and test\n",
    "In Step 2 we load the initial dataset, setting the protected attribute to be age.  We then splits the original dataset into training and testing datasets.  Although we will use only  the training dataset in this tutorial, a normal workflow would also use a test dataset for assessing the efficacy (accuracy, fairness, etc.) during the development of a machine learning model.  Finally, we set two variables (to be used in Step 3) for the privileged (1) and unprivileged (0) values for the age attribute.  These are key inputs for detecting and mitigating bias, which will be Step 3 and Step 4.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_orig = GermanDataset(\n",
    "    protected_attribute_names=['age'],           # this dataset also contains protected\n",
    "                                                 # attribute for \"sex\" which we do not\n",
    "                                                 # consider in this evaluation\n",
    "    privileged_classes=[lambda x: x >= 25],      # age >=25 is considered privileged\n",
    "    features_to_drop=['personal_status', 'sex'] # ignore sex-related attributes\n",
    ")\n",
    "\n",
    "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)\n",
    "\n",
    "privileged_groups = [{'age': 1}]\n",
    "unprivileged_groups = [{'age': 0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aif360.datasets.german_dataset.GermanDataset"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 Compute fairness metric on original training dataset\n",
    "Now that we've identified the protected attribute 'age' and defined privileged and unprivileged values, we can use aif360 to detect bias in the dataset.  One simple test is to compare the percentage of favorable results for the privileged and unprivileged groups, subtracting the former percentage from the latter.   A negative value indicates less favorable outcomes for the unprivileged groups.  This is implemented in the method called mean_difference on the BinaryLabelDatasetMetric class.  The code below performs this check and displays the output, showing that the difference is -0.169905."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between unprivileged and privileged groups = -0.169905\n"
     ]
    }
   ],
   "source": [
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(f\"Difference in mean outcomes between unprivileged and privileged groups = {metric_orig_train.mean_difference():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 Mitigate bias by transforming the original dataset\n",
    "The previous step showed that the privileged group was getting 17% more positive outcomes in the training dataset.   Since this is not desirable, we are going to try to mitigate this bias in the training dataset.  As stated above, this is called _pre-processing_ mitigation because it happens before the creation of the model.  \n",
    "\n",
    "AI Fairness 360 implements several pre-processing mitigation algorithms.  We will choose the Reweighing algorithm [1], which is implemented in the `Reweighing` class in the `aif360.algorithms.preprocessing` package.  This algorithm will transform the dataset to have more equity in positive outcomes on the protected attribute for the privileged and unprivileged groups.\n",
    "\n",
    "We then call the fit and transform methods to perform the transformation, producing a newly transformed training dataset (dataset_transf_train).\n",
    "\n",
    "`[1] F. Kamiran and T. Calders,  \"Data Preprocessing Techniques for Classification without Discrimination,\" Knowledge and Information Systems, 2012.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.96229508, 1.25555556, 0.678     ,\n",
       "       1.100625  , 1.100625  , 0.96229508, 0.96229508, 1.100625  ,\n",
       "       0.96229508, 1.25555556, 1.100625  , 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       1.100625  , 0.96229508, 0.96229508, 0.96229508, 0.678     ,\n",
       "       0.96229508, 0.96229508, 0.678     , 1.100625  , 0.96229508,\n",
       "       0.678     , 0.96229508, 0.96229508, 1.100625  , 0.96229508,\n",
       "       1.100625  , 0.96229508, 0.96229508, 1.25555556, 0.96229508,\n",
       "       0.678     , 1.100625  , 0.96229508, 0.96229508, 1.25555556,\n",
       "       1.100625  , 1.100625  , 0.96229508, 0.96229508, 1.100625  ,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       1.100625  , 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.96229508, 1.100625  , 0.678     , 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 1.25555556,\n",
       "       1.100625  , 0.96229508, 1.100625  , 1.100625  , 0.96229508,\n",
       "       0.96229508, 0.96229508, 1.25555556, 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.678     , 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       1.100625  , 0.96229508, 0.96229508, 1.25555556, 0.96229508,\n",
       "       0.96229508, 1.25555556, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.96229508, 1.100625  , 1.100625  , 0.96229508,\n",
       "       0.96229508, 1.100625  , 1.100625  , 1.25555556, 0.96229508,\n",
       "       0.96229508, 1.100625  , 0.96229508, 0.96229508, 1.25555556,\n",
       "       1.100625  , 0.96229508, 1.25555556, 1.100625  , 0.96229508,\n",
       "       0.96229508, 1.25555556, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.678     , 0.96229508, 0.678     , 0.96229508, 0.96229508,\n",
       "       1.100625  , 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       1.25555556, 0.96229508, 0.96229508, 0.678     , 1.100625  ,\n",
       "       1.100625  , 0.96229508, 0.96229508, 1.100625  , 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.96229508, 1.100625  , 0.96229508,\n",
       "       0.96229508, 1.100625  , 0.96229508, 0.96229508, 0.96229508,\n",
       "       1.100625  , 0.96229508, 0.96229508, 1.100625  , 1.100625  ,\n",
       "       1.100625  , 1.100625  , 0.96229508, 1.100625  , 0.96229508,\n",
       "       0.96229508, 1.25555556, 0.96229508, 1.100625  , 0.96229508,\n",
       "       0.678     , 1.100625  , 1.100625  , 0.96229508, 1.25555556,\n",
       "       0.96229508, 0.96229508, 0.96229508, 1.100625  , 0.96229508,\n",
       "       0.678     , 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       1.100625  , 1.100625  , 1.100625  , 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.678     , 0.96229508, 1.100625  , 0.96229508,\n",
       "       0.96229508, 1.100625  , 0.678     , 1.100625  , 1.25555556,\n",
       "       0.96229508, 1.100625  , 0.96229508, 0.96229508, 0.96229508,\n",
       "       1.100625  , 0.96229508, 1.100625  , 0.96229508, 0.96229508,\n",
       "       1.25555556, 0.96229508, 0.96229508, 0.96229508, 0.678     ,\n",
       "       0.678     , 0.96229508, 1.25555556, 0.96229508, 0.96229508,\n",
       "       0.96229508, 1.25555556, 1.100625  , 1.100625  , 1.25555556,\n",
       "       0.96229508, 0.678     , 1.100625  , 0.96229508, 1.100625  ,\n",
       "       1.25555556, 0.96229508, 0.96229508, 0.96229508, 1.100625  ,\n",
       "       1.100625  , 0.96229508, 0.96229508, 1.100625  , 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.96229508, 1.25555556, 0.96229508, 0.96229508,\n",
       "       1.100625  , 0.96229508, 0.678     , 0.96229508, 1.100625  ,\n",
       "       1.100625  , 1.100625  , 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.96229508, 1.100625  , 1.100625  ,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 1.100625  ,\n",
       "       1.25555556, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.96229508, 1.25555556, 0.96229508, 1.100625  ,\n",
       "       1.25555556, 0.678     , 0.96229508, 1.100625  , 1.100625  ,\n",
       "       1.100625  , 1.100625  , 0.96229508, 0.96229508, 0.96229508,\n",
       "       1.25555556, 1.100625  , 1.100625  , 1.100625  , 0.96229508,\n",
       "       1.100625  , 1.100625  , 0.96229508, 0.96229508, 1.25555556,\n",
       "       0.96229508, 1.25555556, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.96229508, 1.100625  , 0.96229508,\n",
       "       1.100625  , 0.96229508, 1.100625  , 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 1.100625  , 0.96229508, 1.100625  , 1.25555556,\n",
       "       1.100625  , 0.96229508, 0.678     , 1.25555556, 0.96229508,\n",
       "       0.678     , 1.100625  , 0.96229508, 1.100625  , 1.100625  ,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.96229508, 1.100625  , 1.100625  , 1.25555556,\n",
       "       1.25555556, 0.96229508, 1.100625  , 1.100625  , 0.96229508,\n",
       "       0.96229508, 1.100625  , 0.96229508, 1.100625  , 0.678     ,\n",
       "       0.96229508, 1.100625  , 0.96229508, 1.25555556, 0.96229508,\n",
       "       1.100625  , 0.678     , 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.678     , 1.25555556, 0.96229508, 1.25555556, 0.678     ,\n",
       "       1.100625  , 1.100625  , 0.96229508, 0.96229508, 0.678     ,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 1.100625  ,\n",
       "       0.96229508, 0.96229508, 0.678     , 1.25555556, 1.100625  ,\n",
       "       0.96229508, 0.96229508, 0.678     , 0.96229508, 0.96229508,\n",
       "       1.100625  , 1.100625  , 0.96229508, 1.100625  , 1.100625  ,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.678     ,\n",
       "       0.96229508, 0.96229508, 0.96229508, 1.25555556, 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.678     , 0.96229508, 1.100625  ,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 1.100625  , 0.96229508, 1.100625  , 0.678     ,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.96229508, 1.25555556, 0.678     , 1.100625  ,\n",
       "       0.96229508, 1.100625  , 0.96229508, 1.100625  , 0.96229508,\n",
       "       1.25555556, 0.96229508, 0.96229508, 1.25555556, 1.100625  ,\n",
       "       1.100625  , 1.100625  , 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 1.25555556, 0.96229508, 0.96229508, 0.678     ,\n",
       "       1.100625  , 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 1.25555556, 1.100625  , 0.96229508, 0.96229508,\n",
       "       0.96229508, 1.25555556, 0.96229508, 0.96229508, 1.100625  ,\n",
       "       0.96229508, 1.100625  , 1.25555556, 0.96229508, 1.100625  ,\n",
       "       1.25555556, 0.96229508, 1.100625  , 0.96229508, 0.96229508,\n",
       "       1.100625  , 1.100625  , 0.96229508, 0.96229508, 1.100625  ,\n",
       "       1.100625  , 0.96229508, 0.96229508, 0.96229508, 0.678     ,\n",
       "       0.96229508, 0.96229508, 0.96229508, 1.100625  , 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.96229508, 1.25555556, 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 1.100625  , 1.100625  , 0.96229508, 0.96229508,\n",
       "       0.96229508, 1.25555556, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 1.100625  , 0.96229508, 0.96229508, 1.25555556,\n",
       "       0.96229508, 1.100625  , 1.100625  , 0.96229508, 0.96229508,\n",
       "       1.25555556, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.678     , 0.96229508, 1.100625  , 1.25555556, 0.96229508,\n",
       "       0.96229508, 0.96229508, 1.25555556, 0.678     , 0.96229508,\n",
       "       0.96229508, 1.25555556, 0.678     , 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 1.100625  ,\n",
       "       0.96229508, 0.678     , 1.100625  , 1.100625  , 1.100625  ,\n",
       "       0.96229508, 1.100625  , 0.96229508, 1.100625  , 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.678     , 1.100625  ,\n",
       "       0.96229508, 0.96229508, 0.678     , 1.25555556, 0.96229508,\n",
       "       0.96229508, 0.96229508, 1.100625  , 0.96229508, 1.100625  ,\n",
       "       1.100625  , 0.96229508, 0.678     , 0.96229508, 0.96229508,\n",
       "       1.100625  , 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       1.100625  , 0.96229508, 0.678     , 1.100625  , 1.100625  ,\n",
       "       0.678     , 0.96229508, 1.100625  , 0.96229508, 0.678     ,\n",
       "       0.96229508, 1.25555556, 0.678     , 1.25555556, 0.96229508,\n",
       "       0.96229508, 0.96229508, 1.100625  , 0.96229508, 0.96229508,\n",
       "       1.100625  , 1.100625  , 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 1.100625  ,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.678     , 1.25555556, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.678     , 0.96229508,\n",
       "       0.96229508, 1.100625  , 0.678     , 1.100625  , 1.100625  ,\n",
       "       1.25555556, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 1.100625  , 0.96229508, 0.96229508, 1.100625  ,\n",
       "       1.100625  , 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       1.100625  , 0.96229508, 1.25555556, 1.100625  , 0.96229508,\n",
       "       0.678     , 0.96229508, 1.25555556, 0.96229508, 0.96229508,\n",
       "       0.678     , 1.25555556, 1.25555556, 0.96229508, 0.96229508,\n",
       "       0.96229508, 1.100625  , 0.96229508, 1.100625  , 0.96229508,\n",
       "       1.100625  , 1.100625  , 1.100625  , 1.100625  , 0.96229508,\n",
       "       0.96229508, 1.100625  , 1.100625  , 0.96229508, 0.96229508,\n",
       "       0.96229508, 1.25555556, 1.25555556, 0.96229508, 0.96229508])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "                privileged_groups=privileged_groups)\n",
    "dataset_transf_train = RW.fit_transform(dataset_orig_train)\n",
    "dataset_transf_train.instance_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 Compute fairness metric on transformed dataset\n",
    "Now that we have a transformed dataset, we can check how effective it was in removing bias by using the same metric we used for the original training dataset in Step 3.  Once again, we use the function mean_difference in the BinaryLabelDatasetMetric class.   We see the mitigation step was very effective, the difference in mean outcomes is now 0.0.  So we went from a 17% advantage for the privileged group to equality in terms of mean outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Transformed training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between unprivileged and privileged groups = 0.000000\n"
     ]
    }
   ],
   "source": [
    "metric_transf_train = BinaryLabelDatasetMetric(dataset_transf_train, \n",
    "                                               unprivileged_groups=unprivileged_groups,\n",
    "                                               privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Transformed training dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_transf_train.mean_difference())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Evaluate and mitigate bias on the Titanic Dataset\n",
    "\n",
    "[Titanic](https://www.kaggle.com/c/titanic) is a famous competition in Kaggle. However, Titanic models typically rely too heavily on sex as a feature. Your goal in this task is to apply the same procedure above to the titanic dataset (Step 1-5) and compare the accuracy of an original model and the \"fair\" model (Step 6).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat \"Step 1-5\" on the Titanic dataset\n",
    "Please note that `sex` (rather than `age`) is the protected attribute.\n",
    "\n",
    "* Step 1: Write import statements\n",
    "* Step 2: Set bias detection options, load dataset, and split between train and test\n",
    "* Step 3: Compute fairness metric on original training dataset\n",
    "* Step 4: Mitigate bias by transforming the original dataset\n",
    "* Step 5: Compute fairness metric on transformed training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import StandardScaler, LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code\n",
    "titanic_data = pd.read_csv(\"titanic/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sex_to_int(x):\n",
    "    if x == 'male':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare X and y\n",
    "X = titanic_data.drop(['Survived', 'Name', 'Ticket', 'Cabin','PassengerId',], axis=1)\n",
    "X = X[X['Embarked'].notna() & X['Age'].notna()]\n",
    "\n",
    "# Convert X['Sex'] to binary\n",
    "X['Sex'] = X['Sex'].apply(lambda x: sex_to_int(x))\n",
    "X = pd.get_dummies(X, columns=['Embarked'])\n",
    "\n",
    "y = titanic_data['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split our data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale our X values\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert scaled data back into dataframes\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "\n",
    "# Create a BinaryLabelDataset\n",
    "train_df = X_train_scaled_df.copy()\n",
    "train_df['Survived'] = y_train.values\n",
    "\n",
    "test_df = X_test_scaled_df.copy()\n",
    "test_df['Survived'] = y_test.values\n",
    "\n",
    "# aif360_data = BinaryLabelDataset(favorable_label=1, unfavorable_label=0, df=X, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>3</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass   Age  SibSp  Parch     Fare  Sex_female  Sex_male  Embarked_C  \\\n",
       "0         3  22.0      1      0   7.2500       False      True       False   \n",
       "1         1  38.0      1      0  71.2833        True     False        True   \n",
       "2         3  26.0      0      0   7.9250        True     False       False   \n",
       "3         1  35.0      1      0  53.1000        True     False       False   \n",
       "4         3  35.0      0      0   8.0500       False      True       False   \n",
       "..      ...   ...    ...    ...      ...         ...       ...         ...   \n",
       "885       3  39.0      0      5  29.1250        True     False       False   \n",
       "886       2  27.0      0      0  13.0000       False      True       False   \n",
       "887       1  19.0      0      0  30.0000        True     False       False   \n",
       "889       1  26.0      0      0  30.0000       False      True        True   \n",
       "890       3  32.0      0      0   7.7500       False      True       False   \n",
       "\n",
       "     Embarked_Q  Embarked_S  \n",
       "0         False        True  \n",
       "1         False       False  \n",
       "2         False        True  \n",
       "3         False        True  \n",
       "4         False        True  \n",
       "..          ...         ...  \n",
       "885        True       False  \n",
       "886       False        True  \n",
       "887       False        True  \n",
       "889       False       False  \n",
       "890        True       False  \n",
       "\n",
       "[712 rows x 10 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 Compare the performance of the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train two logistic regression models: one on the original training dataset and the other on the transformed dataset. Compare the accuracy of the two models on the same test dataset. Note that reweighting is only applied on the training data **not** on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Braund, Mr. Owen Harris'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jd/f_rvzywd5j7g5f9ckcp7wsxr0000gp/T/ipykernel_94590/2124788363.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Write your code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mog_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mog_model_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mog_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mog_model_fit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aif360/lib/python3.11/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m                 skip_parameter_validation=(\n\u001b[1;32m   1471\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1472\u001b[0m                 )\n\u001b[1;32m   1473\u001b[0m             ):\n\u001b[0;32m-> 1474\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/aif360/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1197\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1201\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m   1202\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aif360/lib/python3.11/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    646\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"estimator\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m                     \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aif360/lib/python3.11/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1259\u001b[0m         raise ValueError(\n\u001b[1;32m   1260\u001b[0m             \u001b[0;34mf\"{estimator_name} requires y to be passed, but the target y is None\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m         )\n\u001b[1;32m   1262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1263\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1264\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m         \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aif360/lib/python3.11/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    994\u001b[0m                         )\n\u001b[1;32m    995\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 998\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    999\u001b[0m                 raise ValueError(\n\u001b[1;32m   1000\u001b[0m                     \u001b[0;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                 ) from complex_warning\n",
      "\u001b[0;32m~/miniconda3/envs/aif360/lib/python3.11/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aif360/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m   2149\u001b[0m     def __array__(\n\u001b[1;32m   2150\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2151\u001b[0m     ) -> np.ndarray:\n\u001b[1;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2153\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2154\u001b[0m         if (\n\u001b[1;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Braund, Mr. Owen Harris'"
     ]
    }
   ],
   "source": [
    "## Write your code\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "og_model = LogisticRegression()\n",
    "og_model_fit = og_model.fit(X_train, y_train)\n",
    "\n",
    "og_model_fit.score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the code in A11-1.ipynb, and submit it to the CourSys activity Assignment 11."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
